{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27e1a3d4",
   "metadata": {},
   "source": [
    "## Import bibliotek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d64c7220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.formula.api import ols # regresja liniowa / metoda najmniejszych kwadratów STATSMODELS\n",
    "from sklearn.linear_model import LinearRegression # regresja liniowa SKLEARN\n",
    "from sklearn.model_selection import train_test_split # funkcja do podziału zbioru\n",
    "from sklearn.metrics import mean_squared_error # metryka z której skorzystamy\n",
    "import seaborn as sns # wizualizacje w Python\n",
    "import matplotlib.pyplot as plt # wizualizacje w Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6748c759",
   "metadata": {},
   "source": [
    "## 1. Wczytanie zbiorów."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1d0fd5",
   "metadata": {},
   "source": [
    "Dla przypomnienia - co udało nam sie ustalić podczas EDA:\n",
    "* `ed` - najmocniejsza zmienna (widzieliśmy to w tabeli korelacji)\n",
    "* `sex` - niezła zmienna (widzieliśmy to na wykresie gęstości dla zmiennej `earn`, którą podzieliliśmy względem płci)\n",
    "* `sex`:`ed` - interakcja, którą odkryliśmy na tym wykresie (`sns.lmplot(data=wages, x='ed', y='earn', hue='sex', aspect=1.5)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e63e0d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "wages = pd.read_csv('dane/wages.txt')\n",
    "wages['height'] = wages['height'] * 2.54 # zamieńmy cale na cm\n",
    "wages = wages.query('earn>1100') # usunięcie wartości odstających"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eb162db",
   "metadata": {},
   "outputs": [],
   "source": [
    "wages['earn_log10'] = np.log10(wages.earn)\n",
    "wages['age_log10'] = np.log10(wages.age)\n",
    "wages['edu_level'] = wages.ed/wages.age # jaki procent swojego życia dana osoba spędziła na edukacji?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1fb555",
   "metadata": {},
   "source": [
    "## 2. Podział zbioru.\n",
    "\n",
    "UWAGA: podział wykonujemy ze względów dydaktycznych - by porównać wyniki dla zbioru uczącego i testowego + pokazać, że model przeucza/nieprzeucza. W rzeczywistej analizie sugerowałbym wykonanie podziału zbioru tuż przed szczegółową eksporacyjną analizą danych (EDA). Wtedy odkrywalibyśmy pewne relacje, badali wstępne hipotezy na zbiorze uczącym, a następnie weryfikowali je na zbiorze walidacyjnym.\n",
    "\n",
    "Sugerowane podejście:\n",
    "1. Odpowiednie wczytanie zbioru\n",
    "    * zadbanie o poprawne wczytanie danych,\n",
    "    * konwersja zmiennych do odpowiednich typów,\n",
    "    * zbadanie braków danych, ich skali i wybranie sposobu ich osbłużenia.\n",
    "2. Podział zbioru:\n",
    "    * podstawowe statystyki, które mogą nam zasugerować sposób podziału (np. względem daty min. i maks.),\n",
    "    * wybór strategii walidacyjnej (jak dzielimy zbiór, jakie proporcje, czy korzystamy ze stratyfikacji, etc.),\n",
    "    * podział zbioru.\n",
    "3. Eksploracyjna analiza danych.\n",
    "    * badanie hipotez,\n",
    "    * odkrywanie zależności,\n",
    "    * odkrywanie interakcji,\n",
    "    * budowa zmiennych.\n",
    "4. Modelowanie.\n",
    "    * uwzględnienie naszych odkryć w modelu,\n",
    "    * próby ulepszenia modelu,\n",
    "    * rzetelna walidacja,\n",
    "    * budowa finalnego modelu.\n",
    "5. Finalny test na zbiorze testowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d0c0feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wages_tr, wages_te = train_test_split(wages, train_size=0.75, random_state=2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11690ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>earn</th>\n",
       "      <th>height</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>ed</th>\n",
       "      <th>age</th>\n",
       "      <th>earn_log10</th>\n",
       "      <th>age_log10</th>\n",
       "      <th>edu_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79571.299011</td>\n",
       "      <td>187.6806</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "      <td>16</td>\n",
       "      <td>49</td>\n",
       "      <td>4.900756</td>\n",
       "      <td>1.690196</td>\n",
       "      <td>0.326531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96396.988643</td>\n",
       "      <td>168.2242</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>16</td>\n",
       "      <td>62</td>\n",
       "      <td>4.984063</td>\n",
       "      <td>1.792392</td>\n",
       "      <td>0.258065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48710.666947</td>\n",
       "      <td>161.9758</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "      <td>4.687624</td>\n",
       "      <td>1.518514</td>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80478.096153</td>\n",
       "      <td>160.5788</td>\n",
       "      <td>female</td>\n",
       "      <td>other</td>\n",
       "      <td>16</td>\n",
       "      <td>95</td>\n",
       "      <td>4.905678</td>\n",
       "      <td>1.977724</td>\n",
       "      <td>0.168421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82089.345498</td>\n",
       "      <td>160.2232</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>17</td>\n",
       "      <td>43</td>\n",
       "      <td>4.914287</td>\n",
       "      <td>1.633468</td>\n",
       "      <td>0.395349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           earn    height     sex   race  ed  age  earn_log10  age_log10  \\\n",
       "0  79571.299011  187.6806    male  white  16   49    4.900756   1.690196   \n",
       "1  96396.988643  168.2242  female  white  16   62    4.984063   1.792392   \n",
       "2  48710.666947  161.9758  female  white  16   33    4.687624   1.518514   \n",
       "3  80478.096153  160.5788  female  other  16   95    4.905678   1.977724   \n",
       "4  82089.345498  160.2232  female  white  17   43    4.914287   1.633468   \n",
       "\n",
       "   edu_level  \n",
       "0   0.326531  \n",
       "1   0.258065  \n",
       "2   0.484848  \n",
       "3   0.168421  \n",
       "4   0.395349  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c093c1a",
   "metadata": {},
   "source": [
    "## 3. Modelowanie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0478916f",
   "metadata": {},
   "source": [
    "### 3.0. Model 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44dab5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37860.99580200818"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wages_tr.earn.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67adb6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = ols(formula='earn ~ 1',\n",
    "              data=wages_tr).fit() # dopasowujemy model do danych uczących / uczymy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e6afcd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    37860.995802\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.params # wyraz wolny z identycznym parametrem, jak średnia dla zmiennej celu!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "411645e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>earn</td>       <th>  R-squared:         </th> <td>   0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>     nan</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 03 Aug 2023</td> <th>  Prob (F-statistic):</th>  <td>   nan</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:32:58</td>     <th>  Log-Likelihood:    </th> <td> -10504.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   894</td>      <th>  AIC:               </th> <td>2.101e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   893</td>      <th>  BIC:               </th> <td>2.101e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     0</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 3.786e+04</td> <td> 1025.390</td> <td>   36.924</td> <td> 0.000</td> <td> 3.58e+04</td> <td> 3.99e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>549.177</td> <th>  Durbin-Watson:     </th> <td>   1.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>6625.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.616</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>15.267</td>  <th>  Cond. No.          </th> <td>    1.00</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   earn   R-squared:                       0.000\n",
       "Model:                            OLS   Adj. R-squared:                  0.000\n",
       "Method:                 Least Squares   F-statistic:                       nan\n",
       "Date:                Thu, 03 Aug 2023   Prob (F-statistic):                nan\n",
       "Time:                        15:32:58   Log-Likelihood:                -10504.\n",
       "No. Observations:                 894   AIC:                         2.101e+04\n",
       "Df Residuals:                     893   BIC:                         2.101e+04\n",
       "Df Model:                           0                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   3.786e+04   1025.390     36.924      0.000    3.58e+04    3.99e+04\n",
       "==============================================================================\n",
       "Omnibus:                      549.177   Durbin-Watson:                   1.997\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6625.118\n",
       "Skew:                           2.616   Prob(JB):                         0.00\n",
       "Kurtosis:                      15.267   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.summary() # podsumowanie dopasowanego modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaee41c",
   "metadata": {},
   "source": [
    "Sprawdźmy jakośc modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb7a1efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE TR: 30641.82\n",
      "MSE TE: 31309.21\n"
     ]
    }
   ],
   "source": [
    "pred_tr = model_0.predict(wages_tr)\n",
    "pred_te = model_0.predict(wages_te)\n",
    "\n",
    "mse_tr = mean_squared_error(wages_tr.earn, pred_tr, squared=False)\n",
    "mse_te = mean_squared_error(wages_te.earn, pred_te, squared=False)\n",
    "\n",
    "print('MSE TR: {}'.format(np.round(mse_tr, 2)))\n",
    "print('MSE TE: {}'.format(np.round(mse_te, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06b8896",
   "metadata": {},
   "source": [
    "### 3.1. Model 1.\n",
    "Zacznijmy od naszej najbardziej perspektywicznej zmiennej - `ed`. Zaczniemy modelowanie od zmiennej celu `earn`, by zademonstrować interpretację działania modelu regresji liniowej.\n",
    "\n",
    "Pierwsze modele zbudujemy z użyciem klasy `ols` z biblioteki Statsmodels. Porównamy ją później z jej odpowiednikiem z `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ca9e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = ols(formula='earn ~ ed',\n",
    "              data=wages_tr).fit() # dopasowujemy model do danych uczących / uczymy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bed9e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>earn</td>       <th>  R-squared:         </th> <td>   0.100</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.099</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   99.44</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 03 Aug 2023</td> <th>  Prob (F-statistic):</th> <td>2.82e-22</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:33:42</td>     <th>  Log-Likelihood:    </th> <td> -10456.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   894</td>      <th>  AIC:               </th> <td>2.092e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   892</td>      <th>  BIC:               </th> <td>2.093e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>-1.843e+04</td> <td> 5728.109</td> <td>   -3.217</td> <td> 0.001</td> <td>-2.97e+04</td> <td>-7186.640</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ed</th>        <td> 4156.1827</td> <td>  416.789</td> <td>    9.972</td> <td> 0.000</td> <td> 3338.181</td> <td> 4974.185</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>529.407</td> <th>  Durbin-Watson:     </th> <td>   2.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>6121.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.503</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.802</td>  <th>  Cond. No.          </th> <td>    81.3</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   earn   R-squared:                       0.100\n",
       "Model:                            OLS   Adj. R-squared:                  0.099\n",
       "Method:                 Least Squares   F-statistic:                     99.44\n",
       "Date:                Thu, 03 Aug 2023   Prob (F-statistic):           2.82e-22\n",
       "Time:                        15:33:42   Log-Likelihood:                -10456.\n",
       "No. Observations:                 894   AIC:                         2.092e+04\n",
       "Df Residuals:                     892   BIC:                         2.093e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept  -1.843e+04   5728.109     -3.217      0.001   -2.97e+04   -7186.640\n",
       "ed          4156.1827    416.789      9.972      0.000    3338.181    4974.185\n",
       "==============================================================================\n",
       "Omnibus:                      529.407   Durbin-Watson:                   2.010\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6121.972\n",
       "Skew:                           2.503   Prob(JB):                         0.00\n",
       "Kurtosis:                      14.802   Cond. No.                         81.3\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.summary() # podsumowanie dopasowanego modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dcd92a",
   "metadata": {},
   "source": [
    "Sprawdźmy jakośc modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4566ee7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE TR: 29064.58\n",
      "MSE TE: 28664.43\n"
     ]
    }
   ],
   "source": [
    "pred_tr = model_1.predict(wages_tr)\n",
    "pred_te = model_1.predict(wages_te)\n",
    "\n",
    "mse_tr = mean_squared_error(wages_tr.earn, pred_tr, squared=False)\n",
    "mse_te = mean_squared_error(wages_te.earn, pred_te, squared=False)\n",
    "\n",
    "print('MSE TR: {}'.format(np.round(mse_tr, 2)))\n",
    "print('MSE TE: {}'.format(np.round(mse_te, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb380d",
   "metadata": {},
   "source": [
    "#### Co widzimy powyżej? Na co warto zwrócić uwagę?\n",
    "* **`Prob (F-statistic)`** - jest to **p-value** dla statystyki F.\n",
    "    * Pomaga nam ocnić, czy model, jako całość jest **istotny statystycznie**.\n",
    "    * Mała wartość statystyki (< 0.05) oznacza, że model jest istotny statystycznie. Innymi słowy: istnieje statystycznie istotna zależność między zmiennymi objaśniającymi, a zmienną celu w modelu.\n",
    "    * Im wartość statystyki bliższa 1, tym większe prawdopodobieństwo, że nie ma istotnej zależności pomiędzy zmiennymi objaśniającymi, a zmienną celu.\n",
    "    * Naszym celem jest budowa modeli, które będą użyteczne. Dążymy do osiągnięcia niskiego poziomu \"Prob (F-statistic)\", mniejszego od 0.05. Tylko wtedy możemy być pewni wyników modelu i wnioskować na jego podstawie o relacjach pomiędzy zmiennymi objaśniającymi, a zmienną celu. \n",
    "* **`coef`** - współczynniki modelu dla poszczególnych zmiennych. Są one kolejnymi beta (beta_0, beta_1, itd.) z równania regresji liniowej.\n",
    "* **`P>|t|`** - **p-value** (nazywana również \"wartością p\") dla poszczególnych współczynników modelu. Podobnie, jak w przypadku \"Prob (F-statistic)\":\n",
    "    *  Mała wartość p-value (< 0.05) oznacza, że zaobserwowany efekt (wpływ zmiennej) jest istotny statystycznie. Innymi słowy: istnieje statystycznie istotna zależność między zmienną objaśniającą, a zmienną celu.\n",
    "    * Im wartość p-value bliższa 1, tym większe prawdopodobieństwo, że nie ma istotnej zależności pomiędzy daną zmienną objaśniającą, a zmienną celu.\n",
    "* **`[0.025 0.975]`** - 95-cio procentowe przedziały ufności dla poszczególnych współczynników modelu.\n",
    "* **`Notes`** - automatycznie wygenerowane notatki dotyczące modelu. Warto zwrócić uwagę, czy nie ma w nich wskazanych żadnych istotnych uwag, lub ostrzeżeń dotyczących modelu.\n",
    "\n",
    "Warto zwrócić uwagę, że model automatycznie dodał wyraz wolny (\"Intercept\"), pomimo iż nie ma go w \"formule\" modelu. Nie wszystkie implementacje regresji liniowej robią to w sposób automatyczny.\n",
    "\n",
    "#### Czym jest istotność statystyczna?\n",
    "Istotność statystyczna w modelu regresji liniowej odnosi się do tego, czy zmienna lub zbiór zmiennych objaśniających ma istotny wpływ na zmienną celu. Innymi słowy, chodzi o ocenę, czy zaobserwowane zależności wynikają z pewnych informacji zawartych w zbiorze, czy też wynikają z przypadku.\n",
    "\n",
    "Istotność statystyczna występuje często w parze z prawdopodobieństwem, tzw. p-value. \"Istotny\" w tym kontekście oznacza, że istnieje niewielkie prawdopodobieństwo popełnienia błędu.\n",
    "\n",
    "Przykład: powyższy model oszacował wartość współczynnika stojącego przy zmiennej `ed` na 4156.18. `P>|t|` (p-value) dla tego współczynnika wynosi 0.00. Oznacza to, że:\n",
    "* istnieje statystycznie istotna zależność między zmienną objaśniającą, a zmienną celu (ponieważ p-value < 0.05),\n",
    "* prawdopodobieństwo, że się mylimy (tj. zależność jednak nie istnieje, podczas, gdy my oceniamy, że istnieje) wynosi 0 (tyle ile wskazane p-value, które w istocie jest TYM prawdopodobieństwem).\n",
    "\n",
    "#### Skąd akurat wartość jako wartość 0.05 rozgraniczająca pomiędzy istotnością statystyczną, a jej brakiem?\n",
    "Wartość 0.05, to tzw. **`alfa`**, a więc zakładany poziom istotności, który jest powszechnie przyjmowany jako próg do podejmowania decyzji o odrzuceniu lub nieodrzuceniu hipotez statystycznych.\n",
    "\n",
    "Alfa jest przyjmowany arbitralnie przez osobę przeprowadzającą analizę/budującą model, a jego wartośc równa 0.05 to przyjęty standard w statystyce.\n",
    "\n",
    "#### Czym jest p-value? \n",
    "Jest to prawdopodobieństwo popełnienia błędu. Jeśli p-value < alfa (zakładany poziom istotności), to  możemy mówić o niewielkim prawdopodobieństwie popełnienia błędu, gdy stwierdzimy, że zaobserwowany efekt istnieje."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7bac5",
   "metadata": {},
   "source": [
    "#### Czym jest istotność statystyczna?\n",
    "Istotność statystyczna w modelu regresji liniowej odnosi się do tego, czy zmienna lub zbiór zmiennych objaśniających ma istotny wpływ na zmienną celu. Innymi słowy, chodzi o ocenę, czy zaobserwowane zależności wynikają z pewnych informacji zawartych w zbiorze, czy też wynikają z przypadku.\n",
    "\n",
    "Istotność statystyczna występuje często w parze z prawdopodobieństwem, tzw. p-value. \"Istotny\" w tym kontekście oznacza, że istnieje niewielkie prawdopodobieństwo popełnienia błędu.\n",
    "\n",
    "Przykład: powyższy model oszacował wartość współczynnika stojącego przy zmiennej `ed` na 4156.18. `P>|t|` (p-value) dla tego współczynnika wynosi 0.00. Oznacza to, że:\n",
    "* istnieje statystycznie istotna zależność między zmienną objaśniającą, a zmienną celu (ponieważ p-value<alfa),\n",
    "* prawdopodobieństwo, że się mylimy (tj. zależność jednak nie istnieje, podczas, gdy my oceniamy, że istnieje) wynosi 0.\n",
    "\n",
    "#### Skąd akurat wartość jako wartość 0.05 rozgraniczająca pomiędzy istotnością statystyczną, a jej brakiem?\n",
    "Wartość 0.05, to tzw. **`alfa`**, a więc zakładany poziom istotności, który jest powszechnie przyjmowany jako próg do podejmowania decyzji o odrzuceniu lub nieodrzuceniu hipotez statystycznych.\n",
    "\n",
    "Alfa jest przyjmowany arbitralnie przez osobę przeprowadzającą analizę/budującą model, a jego wartośc równa 0.05 to przyjęty standard w statystyce.\n",
    "\n",
    "#### Czym jest p-value? \n",
    "Jest to prawdopodobieństwo popełnienia błędu. Jeśli p-value < alfa (zakładany poziom istotności), to  możemy mówić o niewielkim prawdopodobieństwie popełnienia błędu, zakładając, że zaobserwowany efekt istnieje."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee0b5ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Testowanie hipotez\n",
    "\n",
    "Wszystko powyższe możemy odnieść to procesu testowania hipotez. Zawsze zakładamy w nim jakąś hipotezę zerową i hipoteze alternatywną. Nazwijny je kolejno: $H_0$ i $H_1$. Na starcie procesu testowania hipotez przyjmujemy $H_0$. Powszechnie przyjmuje się, że H_0 odnosi się do braku zależności/wpływu/różnicy.\n",
    "![](zdjęcia/court.jpg)\n",
    "Przykładem, który pomoże to zrozumieć jest sądownictwo. Na starcie procesu, zgodnie z zasadą domniemania niewinności uważa się oskarżonego za niewinnego. Dopiero w trakcie trwana procesu wysnuwane są oskarżenia i zbierane dowody na jego winę.\n",
    "\n",
    "Podobnie jest w przypadku testowania hipotez. Na starcie zakłdamy brak związku ($H_0$). Nastpnie poszukujemy dowodów, które pozwalają nam odrzucić $H_0$ i przyjąć $H_1$. By to zrobić dowody muszą być przekonywujące i jednoznaczne. Zgodnie z przyjętym podejściem, maksymalny akceptowalne prawdopodobieństwo popełnienia błędu to 5% (zakładany poziom istotności alfa).\n",
    "\n",
    "Podejście można streścić w następujących krokach:\n",
    "1. Stawiamy hipotezy: $H_0$ i $H_1$.\n",
    "2. Poszukujemy dowodów na prawdziwość $H_1$, odrzucenie $H_0$.\n",
    "3. Wnioskujemy na podstawie zebranych dowodów (im więcej dowodów, tym p-value mniejsze):\n",
    "    * jeśli p-value < alfa, to odrzucamy $H_0$ i przyjmujemy $H_1$,\n",
    "    * jeśli p-value >= alfa, to nie mamy podstaw, by odrzucić $H_0$.\n",
    "    \n",
    "UWAGA: Brak dowodów na przyjęcie $H_1$ (p-value >= alfa) nie oznacza automatycznie, że $H_0$ jest prawdziwe. W takim przypadku nie akceptujemy ani $H_0$, ani $H_1$. $H_0$ pozostaje nieodrzucone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7265970",
   "metadata": {},
   "source": [
    "### Wnioskowanie statystyczne (wnioskowanie parametryczne, na podstawie modelu).\n",
    "W rozważanym przypadku dotyczącym zarobków w NY, nie jestesmy w stanie przeprowadzić ankiet z wszystkimi osobami zamieszkującymi NY. Badamy więc pewną **próbę** z populacji. We wnioskowaniu statystycznym chodzi o to, by powiedzieć coś na temat całej populacji, na podstawie próby, którą dysponujemy.\n",
    "\n",
    "Znamy wzór regresji liniowej: $y = \\beta_0 + \\beta_1 x + \\varepsilon$. Zdefiniujmy i odnieśmy do niego hipotezy w regresji liniowej:\n",
    "\n",
    "* $H_0$ w przypadku parametrów regresji liniowej zakłada, że: $\\beta_1 = 0$. Jeśli $\\beta_1 = 0$ (prosta równoległa do osi x), to oznacza brak związku pomiędzy x i y ($0 x = 0$).\n",
    "* $H_1$ w przypadku parametrów regresji liniowej zakłada, że: $\\beta_1 \\neq 0$.\n",
    "\n",
    "By odrzucić $H_0$ należy wykluczyć możliwość, że prawdziwe $\\beta_1=0$. Jak to zrobić? Model wyznacza przedziały ufności na poziomie 95% dla badango współczynnika, a następnie szacuje, jakie jest prawdopodobieństwo, że $\\beta_1=0$ (dla całej populacji), jeśli zakładane przedziały są prawdziwe.\n",
    "\n",
    "Przeanalizujmy przedziały ufności i współczynnik $\\beta_1$, leżący przy zmiennej `ed`.\n",
    "* współczynnik $\\beta_1$ wynosi 4156.18,\n",
    "* przedziały ufności napoziomie 95% wynoszą [3338.181, 4974.185].\n",
    "\n",
    "Jest bardzo mało prawdopodobne, by prawdziwe $\\beta_1$ (prawdziwe, tj. dla całej populacji) wynosiło 0.000, podczas gdy 95% przedział ufności wynosi [3338.181, 4974.185]. Przedział jest relatywnie wąski i leży \"daleko\" od zera, dlatego model wyznaczył p-value=0.000.\n",
    "\n",
    "W związku z powyższymi kalkulacjami odrzucamy $H_0$ i przyjmujemy $H_1$ z maksymalnym dopuszczalym prawdopodobieństwem popełnienia błędu równy 5% (zakładany poziom istotności alfa, który nie postał przekroczony, bo p-value < alfa).\n",
    "\n",
    "Gdybyśmy mieli ludzkim językiem wydać modelowi polecenie wyznaczenia p-value dla powyższego przykładu, to można by do niego powiedzieć:\n",
    "> Wyznacz prawdopodobieństwo, że $\\beta_1=4156.19$, przy założeniu, że prawdziwe (dla całej populacji) $\\beta_1=0$.\n",
    "\n",
    "W powyższym poleceniu każemy modelowi oszacować, jakie jest prawdopodobieństwo naszej pomyłki w ocenie parametru i relacji pomiędzy zmienną `ed`, a `earn`.\n",
    "* Jeśli prawdopodobieństwo jest duże (>= 0.05), to nie można wykluczyć, że prawdziwe $\\beta_1=0$. Prawdopodobieństwo jest nieakceptowalne duże, by mówić o statystycznie istotnej relacji pomiędzy `ed` i `earn`.\n",
    "* Jeśli prawdopodobieństwo jest małe (< 0.05), to stwierdzamy, iż istnieją przesłanki, że prawdziwe  $\\beta_1\\neq0$. Prawdopodobieństwo popełnienia błędu jest akceptowalnie małe, dlatego mamy podstawy, by wierzyć w statystycznie istotną zalezność między `ed` i `earn`.\n",
    "\n",
    "Dla zmiennej `ed` model wyznaczył prawdopodobieństwo (p-value) równe 0.000, dlatego są minimalne szanse, że prawdziwe $\\beta_1=0$, podczas gdy zaobserwowane $\\beta_1=4156.19$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035217a1",
   "metadata": {},
   "source": [
    "#### Jaka jest zatem relacja między poziomem edukacji (wyrażonym w latach edukacji), a zarobkami?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41866c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>earn</td>       <th>  R-squared:         </th> <td>   0.100</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.099</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   99.44</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 03 Aug 2023</td> <th>  Prob (F-statistic):</th> <td>2.82e-22</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:34:05</td>     <th>  Log-Likelihood:    </th> <td> -10456.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   894</td>      <th>  AIC:               </th> <td>2.092e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   892</td>      <th>  BIC:               </th> <td>2.093e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>-1.843e+04</td> <td> 5728.109</td> <td>   -3.217</td> <td> 0.001</td> <td>-2.97e+04</td> <td>-7186.640</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ed</th>        <td> 4156.1827</td> <td>  416.789</td> <td>    9.972</td> <td> 0.000</td> <td> 3338.181</td> <td> 4974.185</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>529.407</td> <th>  Durbin-Watson:     </th> <td>   2.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>6121.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.503</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.802</td>  <th>  Cond. No.          </th> <td>    81.3</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   earn   R-squared:                       0.100\n",
       "Model:                            OLS   Adj. R-squared:                  0.099\n",
       "Method:                 Least Squares   F-statistic:                     99.44\n",
       "Date:                Thu, 03 Aug 2023   Prob (F-statistic):           2.82e-22\n",
       "Time:                        15:34:05   Log-Likelihood:                -10456.\n",
       "No. Observations:                 894   AIC:                         2.092e+04\n",
       "Df Residuals:                     892   BIC:                         2.093e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept  -1.843e+04   5728.109     -3.217      0.001   -2.97e+04   -7186.640\n",
       "ed          4156.1827    416.789      9.972      0.000    3338.181    4974.185\n",
       "==============================================================================\n",
       "Omnibus:                      529.407   Durbin-Watson:                   2.010\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6121.972\n",
       "Skew:                           2.503   Prob(JB):                         0.00\n",
       "Kurtosis:                      14.802   Cond. No.                         81.3\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82abe72f",
   "metadata": {},
   "source": [
    "* Relacja pomiędzy poziomem edukacji, a zarobkami jest różna od 0.\n",
    "* Edukacja istotnie wpływa na zarobki danej osoby.\n",
    "* Wpływ ten jest istotny statystycznie.\n",
    "* Na podstawie oszacowań modelu stwierdzamy, że jeden dodatkowy rok nauki średnio dodaje do rocznych zarobków 4156.18$.\n",
    "* Mamy 95% ufności, że prawdziwa wartość tego współczynnika (wpływu edukacji na zarobki) leży pomiędzy 3338.181, a 4974.185."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a7e333",
   "metadata": {},
   "source": [
    "### 3.2. Model 2.\n",
    "Dodajmy do modelu kolejną zmienną, która była perspektywiczna (wg naszej oceny podczas EDA) - `sex`, czyli płeć."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56aa4678",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = ols(formula='earn ~ ed + sex',\n",
    "              data=wages_tr).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99ce4456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>earn</td>       <th>  R-squared:         </th> <td>   0.190</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.188</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   104.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 03 Aug 2023</td> <th>  Prob (F-statistic):</th> <td>1.62e-41</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:34:23</td>     <th>  Log-Likelihood:    </th> <td> -10409.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   894</td>      <th>  AIC:               </th> <td>2.082e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   891</td>      <th>  BIC:               </th> <td>2.084e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>-2.386e+04</td> <td> 5465.196</td> <td>   -4.365</td> <td> 0.000</td> <td>-3.46e+04</td> <td>-1.31e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex[T.male]</th> <td> 1.863e+04</td> <td> 1874.665</td> <td>    9.939</td> <td> 0.000</td> <td>  1.5e+04</td> <td> 2.23e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ed</th>          <td> 3981.5404</td> <td>  396.058</td> <td>   10.053</td> <td> 0.000</td> <td> 3204.225</td> <td> 4758.855</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>524.161</td> <th>  Durbin-Watson:     </th> <td>   1.991</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>6584.654</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.435</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>15.371</td>  <th>  Cond. No.          </th> <td>    81.8</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   earn   R-squared:                       0.190\n",
       "Model:                            OLS   Adj. R-squared:                  0.188\n",
       "Method:                 Least Squares   F-statistic:                     104.6\n",
       "Date:                Thu, 03 Aug 2023   Prob (F-statistic):           1.62e-41\n",
       "Time:                        15:34:23   Log-Likelihood:                -10409.\n",
       "No. Observations:                 894   AIC:                         2.082e+04\n",
       "Df Residuals:                     891   BIC:                         2.084e+04\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept   -2.386e+04   5465.196     -4.365      0.000   -3.46e+04   -1.31e+04\n",
       "sex[T.male]  1.863e+04   1874.665      9.939      0.000     1.5e+04    2.23e+04\n",
       "ed           3981.5404    396.058     10.053      0.000    3204.225    4758.855\n",
       "==============================================================================\n",
       "Omnibus:                      524.161   Durbin-Watson:                   1.991\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6584.654\n",
       "Skew:                           2.435   Prob(JB):                         0.00\n",
       "Kurtosis:                      15.371   Cond. No.                         81.8\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e59be",
   "metadata": {},
   "source": [
    "`sex[T.male]` jest widoczne, a gdzie jest `sex[T.female]`? Zawarte w \"Intercept\". Kobiety w tym modelu stanowią tzw. *baseline*, czyli punkt odniesienia. Zawarcie kobiet, jako osobnej zmiennej doprowadziłoby prawdopodobnie do współliniowości. Czemu?\n",
    "* Zmienne kategoryczne są reprezentowane w modelu po zmianie kodowania na tzw. *dummy coding*, a więc zmienne binarne.\n",
    "    * W przypadku zmiennej kategorycznej o 2 poziomach potrzebujemy jednej zmiennej binarnej, by zawrzeć całą wiedzę, jaką ona niesie.\n",
    "    * W przypadku zmiennej kategorycznej o 3 poziomach potrzebujemy dwóch zmiennych binarnych, by zawrzeć całą wiedzę, jaką ona niesie.\n",
    "    * Itd.\n",
    "* Gdy n-poziomów reprezentujemy w postaci n-zmiennych, to każdy z nich możemy ze 100% pewnością zamodelować poprzez pozostałe. Stąd w modelu pojawia się w tego typu przypadkach współliniowość."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60973e16",
   "metadata": {},
   "source": [
    "Sprawdźmy jakośc modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e147831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE TR: 27576.22\n",
      "MSE TE: 28457.36\n"
     ]
    }
   ],
   "source": [
    "pred_tr = model_2.predict(wages_tr)\n",
    "pred_te = model_2.predict(wages_te)\n",
    "\n",
    "mse_tr = mean_squared_error(wages_tr.earn, pred_tr, squared=False)\n",
    "mse_te = mean_squared_error(wages_te.earn, pred_te, squared=False)\n",
    "\n",
    "print('MSE TR: {}'.format(np.round(mse_tr, 2)))\n",
    "print('MSE TE: {}'.format(np.round(mse_te, 2)))\n",
    "\n",
    "# model 1 = earn ~ ed\n",
    "# MSE TR: 29064.58\n",
    "# MSE TE: 28664.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5348e82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept     -23857.872721\n",
       "sex[T.male]    18631.489499\n",
       "ed              3981.540418\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7e6a27",
   "metadata": {},
   "source": [
    "W powyższym modelu widać kilka interesujących informacji:\n",
    "* `Prob (F-statistic):` jest jeszcze mniejsze, niż było\t(2.82e-22 vs 1.62e-41). Model jest jeszcze bardziej istnotny.\n",
    "* Zmieniło się oszacowanie parametru $\\beta$ stojącego przy zmiennej `ed` (4156.1827 vs 3981.5404). Część wpływu na zarobki zabrała mu zmienna `sex`. Odnotujmy, że wraz ze zmianą postaci modelu (np. dodaniem/usunięciem zmiennych) mogą się zmienić oszacowania parametrów.\n",
    "    * Interpretacja współczynnika przy zmiennej `ed`: dodatkowy rok nauki średnio dodaje do rocznych zarobków 3981.54\\$.\n",
    "    * Interpretacja współczynnika przy zmiennej `sex`: mężczyźni zarabiają średnio o 18631.49\\$ więcej niż kobiety.\n",
    "    \n",
    "#### Ćwiczenie 1.\n",
    "Jak oszacować zarobki dla mężczyzny, który przeszedł 16-letnią edukację?\n",
    "\n",
    "$y = \\beta_0 + \\beta_1*sex + \\beta_2*ed$\n",
    "\n",
    "$y = -23857.87 + 18631.49*1 + 3981.54*16$ | przyjmujemy sex=1 dla mężczyzny, zgodnie ze wskazaniami modelu.\n",
    "\n",
    "$y = 58478.26$\n",
    "\n",
    "Mężczyzna, który kształcił się 16 lat zarabia ok. 58 478.26$.\n",
    "\n",
    "#### Ćwiczenie 2.\n",
    "Jak oszacować zarobki dla kobiety, która przeszła 20-letnią edukację?\n",
    "\n",
    "$y = \\beta_0 + \\beta_1*sex + \\beta_2*ed$\n",
    "\n",
    "$y = -23857.87 + 18631.49*0 + 3981.54*20$ | przyjmujemy sex=1 dla mężczyzny, zgodnie ze wskazaniami modelu.\n",
    "\n",
    "$y = 55772.93$\n",
    "\n",
    "Kobieta, który kształciła się 20 lat zarabia ok. 55 772.93$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ff2190",
   "metadata": {},
   "source": [
    "### 3.3. Model 3.\n",
    "Czy pamiętamy, że pod koniec EDA odkryliśmy interakcję pomiędzy `ed` i `sex`? Spróbujmy ją dodać do naszego modelu. By to zrobić, zamiast addytywnego wpływu zmiennych niezależnych (`earn ~ ed + sex`) uwzględniamy w modelu interakcję: `earn ~ ed:sex`, lub `earn ~ ed + sex`. Czym różnią się oba podejścia?\n",
    "\n",
    "Z [dokumentacji Statsmodels](https://www.statsmodels.org/dev/example_formulas.html):\n",
    "> “:” adds a new column to the design matrix with the product of the other two columns. “*” will also include the individual columns that were multiplied together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1016d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# przypomnienie wykresu\n",
    "sns.lmplot(data=wages, x='ed', y='earn', hue='sex', aspect=1.3, height=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498bd2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = ols(formula='earn ~ ed:sex',\n",
    "              data=wages_tr).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c43e2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e772669",
   "metadata": {},
   "source": [
    "Sprawdźmy jakośc modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c7acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tr = model_3.predict(wages_tr)\n",
    "pred_te = model_3.predict(wages_te)\n",
    "\n",
    "mse_tr = mean_squared_error(wages_tr.earn, pred_tr, squared=False)\n",
    "mse_te = mean_squared_error(wages_te.earn, pred_te, squared=False)\n",
    "\n",
    "print('MSE TR: {}'.format(np.round(mse_tr, 2)))\n",
    "print('MSE TE: {}'.format(np.round(mse_te, 2)))\n",
    "\n",
    "# model 1 = earn ~ ed\n",
    "# MSE TR: 29064.58\n",
    "# MSE TE: 28664.43\n",
    "\n",
    "# model 2 = earn ~ ed + sex\n",
    "# MSE TR: 27576.22\n",
    "# MSE TE: 28457.36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2d6864",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01353ec",
   "metadata": {},
   "source": [
    "Szanowanie zarobków dla kobiety z 12-letnim wykształceniem:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1*ed*sex[female] + \\beta_2*ed*sex[male]$\n",
    "\n",
    "$y = -15550.992279 + 3368.676578*12*1 + 4730.911236*12*0$\n",
    "\n",
    "$y = 24873.12$\n",
    "\n",
    "Szanowanie zarobków dla mężczyzny z 5-letnim wykształceniem:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1*ed*sex[female] + \\beta_2*ed*sex[male]$\n",
    "\n",
    "$y = -15550.992279 + 3368.676578*5*0 + 4730.911236*5*1$\n",
    "\n",
    "$y = 8103.56$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d67a968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potwierdźmy powyższe wyniki z pomocą modelu.\n",
    "model_3.predict(pd.DataFrame(\n",
    "    {\n",
    "        'ed': [12, 5],\n",
    "        'sex': ['female', 'male']\n",
    "    }))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904df5ae",
   "metadata": {},
   "source": [
    "### 3.4. Model 4.\n",
    "\n",
    "Sprawdźmy, czy możemy dodać do modelu kolejną zmienną, np. `race`. Podczas EDA wielokrotnie przedziały ufności wskazywały na trudności w oszacowaniu jest realnego związku ze zmienną celu. Czy model zareaguje podobnie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91f7627",
   "metadata": {},
   "outputs": [],
   "source": [
    "wages['is_white'] = np.where(wages.race=='white',\n",
    "                             1,\n",
    "                             np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bf7f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = ols(formula='earn ~ ed:sex + race',\n",
    "              data=wages_tr).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9692cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3f783a",
   "metadata": {},
   "source": [
    "Okazuje się, że współczynniki dla tej zmiennej są nieitotne statystycznie. Powinniśmy ją usunąć z modelu.\n",
    "\n",
    "Pytanie: gdzie jest poziom \"black\" dla zmiennej `race`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdf96d5",
   "metadata": {},
   "source": [
    "### 3.5. Model 5.\n",
    "\n",
    "Widzimy, że najbliżej istotności był poziom \"white\". Czy możemy taki efekt \"wyłuskać\" i zawrzeć w modelu? Tak! :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaaca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wages_tr = wages_tr.copy()\n",
    "wages_te = wages_te.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf685f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wages_tr['race_white'] = wages_tr.race=='white'\n",
    "wages_te['race_white'] = wages_te.race=='white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c90d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = ols(formula='earn ~ ed:sex:race_white',\n",
    "              data=wages_tr).fit()\n",
    "# Najlepsze połączenie to interakcja trzech powyższych czynników."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113c2e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacdb420",
   "metadata": {},
   "source": [
    "Sprawdźmy jakośc modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c205abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tr = model_5.predict(wages_tr)\n",
    "pred_te = model_5.predict(wages_te)\n",
    "\n",
    "mse_tr = mean_squared_error(wages_tr.earn, pred_tr, squared=False)\n",
    "mse_te = mean_squared_error(wages_te.earn, pred_te, squared=False)\n",
    "\n",
    "print('MSE TR: {}'.format(np.round(mse_tr, 2)))\n",
    "print('MSE TE: {}'.format(np.round(mse_te, 2)))\n",
    "\n",
    "# model 1 = earn ~ ed\n",
    "# MSE TR: 29064.58\n",
    "# MSE TE: 28664.43\n",
    "\n",
    "# model 2 = earn ~ ed + sex\n",
    "# MSE TR: 27576.22\n",
    "# MSE TE: 28457.36\n",
    "\n",
    "# model 3 = earn ~ ed:sex\n",
    "# MSE TR: 27554.5\n",
    "# MSE TE: 28245.83"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb180f1",
   "metadata": {},
   "source": [
    "### 3.6. Model 6.\n",
    "\n",
    "Na początku notatnika dodaliśmy zmienną `edu_level`. Czy jest ona istotna? Sprawdźmy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3c1d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6 = ols(formula='earn ~ ed:sex:race_white + edu_level',\n",
    "              data=wages_tr).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2486a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f34ea2",
   "metadata": {},
   "source": [
    "Sprawdźmy jakośc modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa123cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tr = model_6.predict(wages_tr)\n",
    "pred_te = model_6.predict(wages_te)\n",
    "\n",
    "mse_tr = mean_squared_error(wages_tr.earn, pred_tr, squared=False)\n",
    "mse_te = mean_squared_error(wages_te.earn, pred_te, squared=False)\n",
    "\n",
    "print('MSE TR: {}'.format(np.round(mse_tr, 2)))\n",
    "print('MSE TE: {}'.format(np.round(mse_te, 2)))\n",
    "\n",
    "# model 1 = earn ~ ed\n",
    "# MSE TR: 29064.58\n",
    "# MSE TE: 28664.43\n",
    "\n",
    "# model 2 = earn ~ ed + sex\n",
    "# MSE TR: 27576.22\n",
    "# MSE TE: 28457.36\n",
    "\n",
    "# model 3 = earn ~ ed:sex\n",
    "# MSE TR: 27554.5\n",
    "# MSE TE: 28245.83\n",
    "\n",
    "# model 5 = earn ~ ed:sex:race_white\n",
    "# MSE TR: 27197.69\n",
    "# MSE TE: 28052.97\n",
    "\n",
    "# model 6 = earn ~ ed:sex:race_white + edu_level\n",
    "# MSE TR: 26361.12\n",
    "# MSE TE: 27237.29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decffa20",
   "metadata": {},
   "source": [
    "#### Porównanie wyników kolejnych modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fcbf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'MSE': [31309.21, 28664.43, 28457.36, 28245.83, 28052.97, 27237.29]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad5f098",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MSE_IMP'] = df.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecf8226",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MSE_IMP_PRC'] = -100*df.MSE_IMP/df.MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c39ace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6158db52",
   "metadata": {},
   "source": [
    "## 4. Dodatkowe hipotezy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9748e05",
   "metadata": {},
   "source": [
    "### 4.1. Wzrost, a zarobki.\n",
    "Jak to jest z tym wzrostem? Czy wpływa na zarobki, czy też nie? Sprawdźmy to.\n",
    "\n",
    "$H_0$ - wzrost nie wpływa na zarobki.\n",
    "$H_1$ - wzrost wpływa na zarobki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5263b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wzrost_1 = ols(formula='earn ~ height',\n",
    "                   data=wages_tr).fit()\n",
    "model_wzrost_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a700f8f",
   "metadata": {},
   "source": [
    "* p-value < 0.05 - istnieje statystycznie istotna relacja między wzrostem, a zarobkami, prawda?\n",
    "* Każdy dodatkowy cm wzrostu, to ok 848 dolarów do rocznej pensji.\n",
    "* Zwróć jednak uwagę na sekcję \"Notes\". Mamy w niej ostrzeżnie o \"współliniowości lub innym problemie numerycznym\". Współliniowość z jedną zmienną?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaea1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wzrost_2 = ols(formula='earn ~ np.log(height)',\n",
    "                   data=wages_tr).fit()\n",
    "model_wzrost_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec25b5f8",
   "metadata": {},
   "source": [
    "Dodajmy ją zatem do naszego modelu, skoro jest istotna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7a14a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7 = ols(formula='earn ~ ed:sex:race_white + edu_level + np.log(height)',\n",
    "              data=wages_tr).fit()\n",
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55971b9",
   "metadata": {},
   "source": [
    "Jednak jest nieistotna i dodatkowo współczynnik różni się znacząco (1.44e+05 vs 3.219e+04). :( Po co więc cała statystyka i mówienie o tym, że mamy prawo coś wnioskować, skoro wystarczy dodać nowe zmienne i wszystko się zmienia? Jak to wytłumaczyć?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4189ef73",
   "metadata": {},
   "source": [
    "##### Paradoks Simpsona - opis.\n",
    "Powyższe zjawisko nazywa się **paradoksem Simpsona**. Może ono występować m.in. w modelowaniu. Dochodzi w nim do zmiany relacji między zmiennymi, w wyniku wprowadzenia dodatkowej zmiennej do modelu regresji.\n",
    "\n",
    "Efekt ten może prowadzić do odmiennych wniosków dotyczących związku między zmiennymi w zależności od tego, czy analiza jest przeprowadzana dla całego zestawu danych lub podzielonego na grupy.\n",
    "\n",
    "##### Paradoks Simpsona - przyczyna.\n",
    "Przyczyną tego zjawiska są różnice w rozkładach zmiennych między grupami, które to mogą wpływać na wyniki analizy.\n",
    "\n",
    "##### Paradoks Simpsona - rozwiązanie.\n",
    "* Badanie różnych zestawów zmiennych i notowanie, która zmienna najbardziej wpływa na model.\n",
    "* Wnikliwa interpretacja wyników modelu, szczególnie w przypadku, gdy dane są podzielone na różne grupy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b7dcc9",
   "metadata": {},
   "source": [
    "### 4.2. Regresja liniowa w sklearn.\n",
    "\n",
    "Spróbujmy odtworzyć np. ten model: `earn ~ ed + sex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ab789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wages_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e9019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sklearn = LinearRegression()\n",
    "# model_sklearn.fit(wages_tr[['ed', 'sex']], wages_tr[['earn']]) # ta linia zwróci błąd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35d342e",
   "metadata": {},
   "source": [
    "Wszystkie dane, jakich używamy w modelach z biblioteki sklear, muszą być przygotowanie i sprowadzone do postaci wartości numerycznych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf46e866",
   "metadata": {},
   "outputs": [],
   "source": [
    "wages_tr['sex_male'] = pd.get_dummies(wages_tr.sex, drop_first=True)\n",
    "wages_te['sex_male'] = pd.get_dummies(wages_te.sex, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d0fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sklearn.fit(wages_tr[['ed', 'sex_male']], wages_tr[['earn']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821f7cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podejrzyjmy co możemy z niego wyciągnąć.\n",
    "dir(model_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282d0509",
   "metadata": {},
   "source": [
    "Wyciągnijmy z niego współczynniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd19ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sklearn.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d1ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sklearn.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1e6586",
   "metadata": {},
   "source": [
    "Poniżej, dla przypomnienia, współczynniki modelu 2.\n",
    "```\n",
    "Intercept     -23857.872721\n",
    "sex[T.male]    18631.489499\n",
    "ed              3981.540418\n",
    "```\n",
    "Są identyczne, jednak sam sposób budowania modelu dosyć znacząco się różni.\n",
    "* Nie możemy definiować modelu poprzez \"formułę\".\n",
    "* Musimy obsłużyć zmienne kategoryczne.\n",
    "* Musimy obsłużyć braki danych.\n",
    "* Nie mamy dostępu do p-values dla modelu. Nie wiemy zatem, czy model jest istotny, czy nie.\n",
    "* Nie mamy dostępu do p-values dla poszczególnych zmiennych. Nie wiemy zatem, które zmienne są istotne, a które nie.\n",
    "\n",
    "Część powyższych da się obejść, ale jest to nieco problematyczne. Przykład dla modelu 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a917a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from patsy import dmatrices\n",
    "formula = 'earn ~ ed:sex:race_white + edu_level'\n",
    "y, X = dmatrices(formula, wages_tr, return_type='dataframe')\n",
    "\n",
    "model_sklearn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fe468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sklearn.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da17e3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sklearn.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6aedad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.params # przypomnienie parametrów dla modelu 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c5e5c8",
   "metadata": {},
   "source": [
    "### 4.3. Selekcja zmiennych w regresji liniowej.\n",
    "1. **Podejście eksperckie, bazowanie na wiedzy branżowej** - polega na skonsultowaniu się z ekspertem w danej dziedzinie (chyba że sami nim jesteśmy).\n",
    "2. **Metody automatycznej selekcji zmiennych**  - istnieją wpubowane w regresję liniową metody selekcji zmiennych, np. LASSO, która automatycznie usuwa ze zbioru nadmiarowe zmienne.\n",
    "    * Lasso w sklearn: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n",
    "    * Lasso w statsmodels: https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.fit_regularized.html\n",
    "3. **Bazująca na danych** - istnieją krokowe metody selekcji zmiennych, np. .\n",
    "    * Wybierasz statystykę, którą mierzysz dopasowanie modelu do danych.\n",
    "    * *Backward selection* - zaczynając od modelu ze wszystkimi zmiennymi, następnie redukujesz kolejne (najsłabsze) zmienne tak długo, jak długo poprawia się wynik modelu.\n",
    "    * *Forward selection* - zaczynając od pustego modelu, następnie dodajesz kolejne (najmnocniejsze) zmienne tak długo, jak długo poprawia się wynik modelu.\n",
    "    * Oba powyższe podejścia są dostępne:\n",
    "        * w bibliotece `mlxtend`: https://rasbt.github.io/mlxtend/api_subpackages/mlxtend.feature_selection/#sequentialfeatureselector\n",
    "        * w bibliotece `sklearn`: https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3832e4",
   "metadata": {},
   "source": [
    "![](zdjęcia/stepwise.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1bb01a",
   "metadata": {},
   "source": [
    "Źródła:\n",
    "* Zdjęcie: https://pixabay.com/illustrations/justice-straight-jurisdiction-2071539/\n",
    "* Paradoks Simpsona: https://pl.wikipedia.org/wiki/Paradoks_Simpsona\n",
    "* Forward Stepwise Selection: https://github.com/arpanganguli/ISLP/blob/master/Chapter%207/Applied%20Exercises/10.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
